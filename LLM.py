import gradio as gr
from openai import OpenAI
import os
from typing import List, Dict, Tuple, Generator
import uuid
import datetime
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ¨¡å‹é…ç½®
MODELS = {
    "DeepSeek": {
        "api_key": os.getenv("DEEPSEEK_API_KEY"),
        "base_url": "https://api.deepseek.com",
        "model_name": "deepseek-chat"
    },
    "OpenAI": {
        "api_key": os.getenv("OPENAI_API_KEY"),
        "base_url": "https://api.openai.com/v1",
        "model_name": "gpt-3.5-turbo"
    }
}

# å¯¹è¯å†å²å­˜å‚¨
conversations = {}
current_conversation_id = None


def get_client(model: str):
    """åˆ›å»ºæŒ‡å®šæ¨¡å‹çš„å®¢æˆ·ç«¯"""
    config = MODELS[model]
    return OpenAI(
        api_key=config["api_key"],
        base_url=config["base_url"]
    )


def get_current_conversation() -> Dict:
    global current_conversation_id, conversations
    if current_conversation_id is None:
        new_conversation()
    return conversations[current_conversation_id]


def new_conversation():
    global current_conversation_id, conversations
    conv_id = str(uuid.uuid4())
    conversations[conv_id] = {
        "id": conv_id,
        "title": f"æ–°å¯¹è¯ {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "messages": [{"role": "system", "content": "You are a helpful assistant."}],
        "model": "DeepSeek"
    }
    current_conversation_id = conv_id
    return conv_id


def call_model_api(model: str, messages: List[Dict[str, str]], stream: bool) -> Generator[str, None, None] or str:
    """ä½¿ç”¨OpenAI SDKè°ƒç”¨API"""
    if model not in MODELS:
        return f"é”™è¯¯: æœªçŸ¥æ¨¡å‹ {model}"

    if not MODELS[model]["api_key"]:
        return f"é”™è¯¯: æœªé…ç½® {model} API å¯†é’¥"

    try:
        client = get_client(model)
        response = client.chat.completions.create(
            model=MODELS[model]["model_name"],
            messages=messages,
            temperature=0.7,
            max_tokens=2048,
            stream=stream
        )

        if stream:
            # å¯¹äºæµå¼å“åº”ï¼Œæˆ‘ä»¬è¿”å›ä¸€ä¸ªç”Ÿæˆå™¨
            return response
        else:
            # å¯¹äºéæµå¼å“åº”ï¼Œç›´æ¥è¿”å›å®Œæ•´å†…å®¹
            return response.choices[0].message.content
    except Exception as e:
        return f"APIè°ƒç”¨å‡ºé”™: {str(e)}"


def chat_with_history(
    user_input: str,
    chat_history: List[Dict[str, str]],  # æ”¹ä¸ºå­—å…¸åˆ—è¡¨æ ¼å¼
    model: str,
    stream: bool
) -> Generator[Tuple[str, List[Dict[str, str]]], None, None] or Tuple[str, List[Dict[str, str]]]:
    """å¤„ç†å¯¹è¯å¹¶è·å–å›å¤ï¼ˆé€‚é… type='messages' æ ¼å¼ï¼‰"""
    conversation = get_current_conversation()

    # æ›´æ–°å¯¹è¯æ ‡é¢˜ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
    if len(conversation["messages"]) == 1:  # åªæœ‰systemæ¶ˆæ¯
        conversation["title"] = user_input[:30] + "..." if len(user_input) > 30 else user_input

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    conversation["messages"].append({"role": "user", "content": user_input})

    # è°ƒç”¨API
    api_response = call_model_api(model, conversation["messages"], stream)

    if stream:
        # æµå¼å¤„ç†
        chat_history.append({"role": "user", "content": user_input})  # å…ˆæ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        chat_history.append({"role": "assistant", "content": ""})  # åˆå§‹åŒ–ç©ºAIå›å¤
        partial_message = ""

        # éå†æµå¼å“åº”
        for chunk in api_response:
            if chunk.choices[0].delta.content:
                partial_message += chunk.choices[0].delta.content
                # æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆAIå›å¤ï¼‰
                chat_history[-1]["content"] = partial_message
                yield "", chat_history  # è¿”å›æ›´æ–°åçš„èŠå¤©è®°å½•

        # æµå¼ç»“æŸåï¼Œä¿å­˜å®Œæ•´æ¶ˆæ¯åˆ°å¯¹è¯å†å²
        conversation["messages"].append({"role": "assistant", "content": partial_message})
    else:
        # éæµå¼å¤„ç†
        bot_response = api_response
        # æ·»åŠ åŠ©æ‰‹å›å¤
        conversation["messages"].append({"role": "assistant", "content": bot_response})
        # è¿”å›Gradioæ ¼å¼ (æ¸…ç©ºè¾“å…¥æ¡†, æ›´æ–°èŠå¤©å†å²)
        chat_history.append({"role": "user", "content": user_input})
        chat_history.append({"role": "assistant", "content": bot_response})
        return "", chat_history


def load_conversation(conv_id: str) -> Tuple[List[Dict[str, str]], str]:
    """åŠ è½½ç‰¹å®šå¯¹è¯ï¼ˆé€‚é… type='messages' æ ¼å¼ï¼‰"""
    global current_conversation_id
    current_conversation_id = conv_id
    conversation = conversations[conv_id]

    # è½¬æ¢ä¸ºGradioæ ¼å¼ (è·³è¿‡systemæ¶ˆæ¯)
    chat_history = []
    messages = conversation["messages"][1:]  # è·³è¿‡systemæ¶ˆæ¯
    for i in range(0, len(messages) - 1, 2):
        if messages[i]['role'] == 'user' and i + 1 < len(messages):
            user_msg = {"role": "user", "content": messages[i]['content']}
            bot_msg = {"role": "assistant", "content": messages[i + 1]['content']}
            chat_history.extend([user_msg, bot_msg])  # ä¾æ¬¡æ·»åŠ ç”¨æˆ·å’ŒAIæ¶ˆæ¯

    return chat_history, conversation["model"]


def update_conversation_list():
    """æ›´æ–°å¯¹è¯åˆ—è¡¨"""
    return gr.update(choices=[(conv["title"], conv["id"]) for conv in sorted(
        conversations.values(),
        key=lambda x: len(x["messages"]),
        reverse=True
    )], value=current_conversation_id)


def delete_conversation(conv_id: str):
    """åˆ é™¤å¯¹è¯"""
    global current_conversation_id
    if conv_id in conversations:
        del conversations[conv_id]
        if current_conversation_id == conv_id:
            current_conversation_id = new_conversation()
    return update_conversation_list()


# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="DeepSeek èŠå¤©åŠ©æ‰‹", css="""
    .gradio-container { max-width: 1200px !important }
    .conversation-list { height: 500px !important; overflow-y: auto !important }
""") as demo:
    with gr.Row():
        # å·¦ä¾§è¾¹æ 
        with gr.Column(scale=1, min_width=250):
            gr.Markdown("### æ¨¡å‹è®¾ç½®")
            model_dropdown = gr.Dropdown(
                choices=list(MODELS.keys()),
                value="DeepSeek",
                label="é€‰æ‹©æ¨¡å‹"
            )

            # æ·»åŠ æµå¼è¾“å‡ºå¼€å…³
            stream_checkbox = gr.Checkbox(
                label="å¯ç”¨æµå¼è¾“å‡º",
                value=True,
                interactive=True
            )

            gr.Markdown("### å¯¹è¯ç®¡ç†")
            with gr.Row():
                new_chat_btn = gr.Button("+ æ–°å¯¹è¯", variant="primary")
                delete_btn = gr.Button("ğŸ—‘ï¸", variant="secondary")

            conversation_list = gr.Radio(
                label="å†å²å¯¹è¯",
                interactive=True,
                elem_classes=["conversation-list"]
            )

        # å³ä¾§ä¸»èŠå¤©åŒº
        with gr.Column(scale=4):
            chatbot = gr.Chatbot(
                elem_id="chatbot",
                height=600,
                show_copy_button=True,
                type="messages"
            )

            with gr.Row():
                message = gr.Textbox(
                    placeholder="è¾“å…¥æ¶ˆæ¯...",
                    show_label=False,
                    container=False,
                    autofocus=True,
                    scale=7
                )
                submit_btn = gr.Button("å‘é€", variant="primary", scale=1)

            gr.Markdown("""
            <div style="text-align: center; color: #888; margin-top: 10px;">
            æ³¨æ„: AIå¯èƒ½ä¼šäº§ç”Ÿä¸å‡†ç¡®æˆ–è¯¯å¯¼æ€§çš„ä¿¡æ¯
            </div>
            """)

    # ç»„ä»¶äº¤äº’
    submit_btn.click(
        fn=chat_with_history,
        inputs=[message, chatbot, model_dropdown, stream_checkbox],
        outputs=[message, chatbot]
    ).then(
        fn=update_conversation_list,
        outputs=conversation_list
    )

    message.submit(
        fn=chat_with_history,
        inputs=[message, chatbot, model_dropdown, stream_checkbox],
        outputs=[message, chatbot]
    ).then(
        fn=update_conversation_list,
        outputs=conversation_list
    )

    new_chat_btn.click(
        fn=new_conversation,
        outputs=None
    ).then(
        fn=lambda: ([], "DeepSeek"),
        outputs=[chatbot, model_dropdown]
    ).then(
        fn=update_conversation_list,
        outputs=conversation_list
    )

    conversation_list.change(
        fn=load_conversation,
        inputs=conversation_list,
        outputs=[chatbot, model_dropdown]
    )

    delete_btn.click(
        fn=delete_conversation,
        inputs=conversation_list,
        outputs=conversation_list
    ).then(
        fn=lambda: ([], "DeepSeek"),
        outputs=[chatbot, model_dropdown]
    )

    # åˆå§‹åŒ–
    demo.load(
        fn=new_conversation,
        outputs=None
    ).then(
        fn=update_conversation_list,
        outputs=conversation_list
    )

if __name__ == "__main__":
    demo.launch()
